{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ee4b1-b1d6-48ae-ab2f-fcf4916bd034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"ticks\", rc={'axes.formatter.limits': (-4, 5)}, font_scale=1.1)\n",
    "figsize=(4.8*1/0.618,4.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91730b-8b87-430d-8937-8ade1d94c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"spider\": [\"spider\", \"spider_syn\", \"spider_realistic\", \"spider_dr\"],\n",
    "    \"bird\": [\"bird\"],\n",
    "    \"fiben\": [\"fiben\"],\n",
    "}\n",
    "result_dirs = {\n",
    "    \"spider\": Path(\"../results/test/silver-sun-65/k5ou2ykv\"),\n",
    "    \"bird\": Path(\"../results/test/happy-dew-65/ey4tt3n2\"),\n",
    "    \"fiben\": Path(\"../results/test/electric-donkey-66/sj2wkc2b\"),\n",
    "}\n",
    "pds = []\n",
    "N = 51\n",
    "methods = [\"DBCᴏᴘɪʟᴏᴛ\", \"DPR\", \"CRUSH$_{\\mathrm{SXFMR}}$\", \"CRUSH$_{\\mathrm{BM25}}$\", \"SXFMR\", \"BM25\"]\n",
    "for method in methods:\n",
    "    scores = {\n",
    "        \"P\": Counter(),\n",
    "        \"R\": Counter(),\n",
    "        \"n\": Counter(),\n",
    "    }\n",
    "    for dataset, tests in datasets.items():\n",
    "        for test in tests:\n",
    "            if method == \"DPR\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_dense_true.json\"\n",
    "            elif method == \"CRUSH$_{\\mathrm{BM25}}$\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"crush4sql_{test}_sparse_false.json\"\n",
    "            elif method == \"CRUSH$_{\\mathrm{SXFMR}}$\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"crush4sql_{test}_dense_false.json\"\n",
    "            elif method == \"SXFMR\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_dense_false.json\"\n",
    "            elif method == \"BM25\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_sparse_false.json\"\n",
    "            elif method == \"DBCᴏᴘɪʟᴏᴛ\":\n",
    "                result_file = result_dirs[dataset] / f'{test.replace(dataset, \"test\")}.json'\n",
    "\n",
    "            with result_file.open() as file:\n",
    "                results = json.load(file)\n",
    "\n",
    "            for it in results:\n",
    "                gold_schema = it[\"schema\"]\n",
    "                gold_tables = [\n",
    "                    f'{gold_schema[\"database\"]}.{tbl[\"name\"]}'\n",
    "                    for tbl in gold_schema[\"metadata\"]\n",
    "                ]\n",
    "                gold = set(gold_tables)\n",
    "\n",
    "                pred_dbs = []\n",
    "                pred_tables = []\n",
    "                for pred in it[\"pred_schemas\"]:\n",
    "                    pred_dbs.append(pred[\"database\"])\n",
    "                    pred_tables.extend(\n",
    "                        f'{pred[\"database\"]}.{tbl}'\n",
    "                        for tbl in pred[\"tables\"]\n",
    "                    )\n",
    "\n",
    "                for k in range(1, N):\n",
    "                    cands = set(pred_tables[:k])\n",
    "                    tp = len(cands & gold)\n",
    "                    p_k = tp / len(cands) if len(cands) else 0\n",
    "                    r_k = tp / len(gold) if len(gold) else 0\n",
    "                    scores[\"P\"][k] += p_k\n",
    "                    scores[\"R\"][k] += r_k\n",
    "                    scores[\"n\"][k] += 1\n",
    "\n",
    "            recalls = []\n",
    "            K = []\n",
    "            for k in range(1, N):\n",
    "                recalls.append(scores[\"R\"][k] / scores[\"n\"][k])\n",
    "                K.append(k)\n",
    "    \n",
    "            pds.append(pd.DataFrame({\"Recall@$k$\": recalls, \"$k$\": K, \"Method\": [method]*len(precisions)}))\n",
    "\n",
    "pr = pd.concat(pds, ignore_index=True)\n",
    "plt.figure(figsize=figsize)\n",
    "sns.lineplot(data=pr, x=\"$k$\", y=\"Recall@$k$\", hue=\"Method\", style=\"Method\")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('recall_curve.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95cfd32-e127-47a5-81bd-eb5e3dfc43f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "datasets = {\n",
    "    \"spider\": [\"spider\", \"spider_syn\", \"spider_realistic\", \"spider_dr\"],\n",
    "    \"bird\": [\"bird\"],\n",
    "    \"fiben\": [\"fiben\"],\n",
    "}\n",
    "result_dirs = {\n",
    "    \"spider\": Path(\"../results/test/silver-sun-65/k5ou2ykv\"),\n",
    "    \"bird\": Path(\"../results/test/happy-dew-65/ey4tt3n2\"),\n",
    "    \"fiben\": Path(\"../results/test/electric-donkey-66/sj2wkc2b\"),\n",
    "}\n",
    "pds = []\n",
    "N = 16\n",
    "methods = [\"DBCᴏᴘɪʟᴏᴛ\", \"DPR\", \"CRUSH$_{\\mathrm{SXFMR}}$\", \"CRUSH$_{\\mathrm{BM25}}$\", \"SXFMR\", \"BM25\"]\n",
    "for method in methods:\n",
    "    scores = {\n",
    "        \"AP\": Counter(),\n",
    "        \"n\": Counter(),\n",
    "    }\n",
    "    for dataset, tests in datasets.items():\n",
    "        with Path(f\"../data/{dataset}/schemas.json\").open(\"r\") as f:\n",
    "            schemas = json.load(f)\n",
    "            \n",
    "        for test in tests:\n",
    "            if method == \"DPR\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_dense_true.json\"\n",
    "            elif method == \"CRUSH$_{\\mathrm{BM25}}$\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"crush4sql_{test}_sparse_false.json\"\n",
    "            elif method == \"CRUSH$_{\\mathrm{SXFMR}}$\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"crush4sql_{test}_dense_false.json\"\n",
    "            elif method == \"SXFMR\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_dense_false.json\"\n",
    "            elif method == \"BM25\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_sparse_false.json\"\n",
    "            elif method == \"DBCᴏᴘɪʟᴏᴛ\":\n",
    "                result_file = result_dirs[dataset] / f'{test.replace(dataset, \"test\")}.json'\n",
    "\n",
    "            with result_file.open() as file:\n",
    "                results = json.load(file)\n",
    "\n",
    "            for it in results:\n",
    "                gold_schema = it[\"schema\"]\n",
    "                gold_tables = [\n",
    "                    f'{gold_schema[\"database\"]}.{tbl[\"name\"]}'\n",
    "                    for tbl in gold_schema[\"metadata\"]\n",
    "                ]\n",
    "                gold = set(gold_tables)\n",
    "\n",
    "                pred_dbs = []\n",
    "                pred_tables = []\n",
    "                for pred in it[\"pred_schemas\"]:\n",
    "                    pred_dbs.append(pred[\"database\"])\n",
    "                    pred_tables.extend(\n",
    "                        f'{pred[\"database\"]}.{tbl}'\n",
    "                        for tbl in pred[\"tables\"]\n",
    "                    )\n",
    "\n",
    "                Ps, Rs = [1], [0]\n",
    "                for k in range(1, N):\n",
    "                    cands = set(pred_tables[:k])\n",
    "                    tp = len(cands & gold)\n",
    "                    p_k = tp / len(cands) if len(cands) else 0\n",
    "                    r_k = tp / len(gold) if len(gold) else 0\n",
    "\n",
    "                    Ps.append(p_k)\n",
    "                    Rs.append(r_k)\n",
    "                    \n",
    "                AP = auc(Rs, Ps)\n",
    "                scores[\"AP\"][len(schemas[gold_schema[\"database\"]])] += AP\n",
    "                scores[\"n\"][len(schemas[gold_schema[\"database\"]])] += 1\n",
    "                \n",
    "    mAP = []\n",
    "    K = []\n",
    "    for k in range(20):\n",
    "        if scores[\"n\"][k] != 0:\n",
    "            mAP.append(scores[\"AP\"][k] / scores[\"n\"][k])\n",
    "            K.append(k)\n",
    "\n",
    "    pds.append(pd.DataFrame({\"mAP\": mAP, \"Table Number\": K, \"Method\": [method]*len(K)}))\n",
    "\n",
    "pr = pd.concat(pds, ignore_index=True)\n",
    "plt.figure(figsize=figsize)\n",
    "sns.lineplot(data=pr, x=\"Table Number\", y=\"mAP\", hue=\"Method\", style=\"Method\", marker='o')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('table_number.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401ed79-9b3f-4d09-87bb-40555b86329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given data for Database Recall@1 and Table Recall@5\n",
    "data_recall_1 = {\n",
    "    \"Dataset\": ['Spider', 'Bird', 'Fiben'],\n",
    "    \"5000\": [50.68, 70.99, 100],\n",
    "    \"10000\": [72.15, 79.79, 100],\n",
    "    \"20000\": [77.66, 85.07, 100],\n",
    "    \"40000\": [82.01, 88.14, 100],\n",
    "    \"80000\": [85.29, 89.11, 100],\n",
    "    \"100000\": [84.43, 88.85, 100]\n",
    "}\n",
    "\n",
    "data_recall_5 = {\n",
    "    \"Dataset\": ['Spider', 'Bird', 'Fiben'],\n",
    "    \"5000\": [33.1, 40.9, 22.7],\n",
    "    \"10000\": [58.85, 54.23, 30.29],\n",
    "    \"20000\": [68.12, 61.67, 35.9],\n",
    "    \"40000\": [72.72, 65.7, 33.71],\n",
    "    \"80000\": [77.44, 70.09, 34.28],\n",
    "    \"100000\": [76.55, 70.43, 35.99]\n",
    "}\n",
    "\n",
    "# Convert dictionaries to pandas DataFrames for plotting\n",
    "df_recall_1 = pd.DataFrame(data_recall_1).melt(id_vars=['Dataset'], var_name='# Synthetic Data', value_name='Recall@1')\n",
    "df_recall_5 = pd.DataFrame(data_recall_5).melt(id_vars=['Dataset'], var_name='# Synthetic Data', value_name='Recall@5')\n",
    "\n",
    "df_recall_1 = df_recall_1.astype({\"# Synthetic Data\": int})\n",
    "df_recall_5 = df_recall_5.astype({\"# Synthetic Data\": int})\n",
    "\n",
    "# Now let's plot using seaborn\n",
    "plt.tight_layout()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9.6,4.8), constrained_layout=True)\n",
    "\n",
    "# Plot recall@1\n",
    "sns.lineplot(x='# Synthetic Data', y='Recall@1', hue='Dataset', data=df_recall_1, marker='o', ax=axs[0])\n",
    "axs[0].set_title('Database')\n",
    "\n",
    "# Plot recall@5\n",
    "sns.lineplot(x='# Synthetic Data', y='Recall@5', hue='Dataset', data=df_recall_5, marker='o', ax=axs[1])\n",
    "axs[1].set_title('Table')\n",
    "\n",
    "sns.despine()\n",
    "plt.savefig('data_number.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0fadd7-03e6-48ea-b9a6-1e2da132b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's plot using seaborn\n",
    "plt.tight_layout()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(4.8*2*1.2,4.8), constrained_layout=True)\n",
    "\n",
    "datasets = {\n",
    "    \"spider\": [\"spider\", \"spider_syn\", \"spider_realistic\", \"spider_dr\"],\n",
    "    \"bird\": [\"bird\"],\n",
    "    \"fiben\": [\"fiben\"],\n",
    "}\n",
    "result_dirs = {\n",
    "    \"spider\": Path(\"../results/test/silver-sun-65/k5ou2ykv\"),\n",
    "    \"bird\": Path(\"../results/test/happy-dew-65/ey4tt3n2\"),\n",
    "    \"fiben\": Path(\"../results/test/electric-donkey-66/sj2wkc2b\"),\n",
    "}\n",
    "pds = []\n",
    "N = 51\n",
    "methods = [\"DBCᴏᴘɪʟᴏᴛ\", \"DPR\", \"CRUSH$_{\\mathrm{SXFMR}}$\", \"CRUSH$_{\\mathrm{BM25}}$\", \"SXFMR\", \"BM25\"]\n",
    "for method in methods:\n",
    "    scores = {\n",
    "        \"P\": Counter(),\n",
    "        \"R\": Counter(),\n",
    "        \"n\": Counter(),\n",
    "    }\n",
    "    for dataset, tests in datasets.items():\n",
    "        for test in tests:\n",
    "            if method == \"DPR\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_dense_true.json\"\n",
    "            elif method == \"CRUSH$_{\\mathrm{BM25}}$\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"crush4sql_{test}_sparse_false.json\"\n",
    "            elif method == \"CRUSH$_{\\mathrm{SXFMR}}$\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"crush4sql_{test}_dense_false.json\"\n",
    "            elif method == \"SXFMR\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_dense_false.json\"\n",
    "            elif method == \"BM25\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_sparse_false.json\"\n",
    "            elif method == \"DBCᴏᴘɪʟᴏᴛ\":\n",
    "                result_file = result_dirs[dataset] / f'{test.replace(dataset, \"test\")}.json'\n",
    "\n",
    "            with result_file.open() as file:\n",
    "                results = json.load(file)\n",
    "\n",
    "            for it in results:\n",
    "                gold_schema = it[\"schema\"]\n",
    "                gold_tables = [\n",
    "                    f'{gold_schema[\"database\"]}.{tbl[\"name\"]}'\n",
    "                    for tbl in gold_schema[\"metadata\"]\n",
    "                ]\n",
    "                gold = set(gold_tables)\n",
    "\n",
    "                pred_dbs = []\n",
    "                pred_tables = []\n",
    "                for pred in it[\"pred_schemas\"]:\n",
    "                    pred_dbs.append(pred[\"database\"])\n",
    "                    pred_tables.extend(\n",
    "                        f'{pred[\"database\"]}.{tbl}'\n",
    "                        for tbl in pred[\"tables\"]\n",
    "                    )\n",
    "\n",
    "                for k in range(1, N):\n",
    "                    cands = set(pred_tables[:k])\n",
    "                    tp = len(cands & gold)\n",
    "                    p_k = tp / len(cands) if len(cands) else 0\n",
    "                    r_k = tp / len(gold) if len(gold) else 0\n",
    "                    scores[\"P\"][k] += p_k\n",
    "                    scores[\"R\"][k] += r_k\n",
    "                    scores[\"n\"][k] += 1\n",
    "\n",
    "            recalls = []\n",
    "            K = []\n",
    "            for k in range(1, N):\n",
    "                recalls.append(scores[\"R\"][k] / scores[\"n\"][k])\n",
    "                K.append(k)\n",
    "    \n",
    "            pds.append(pd.DataFrame({\"Recall@$k$\": recalls, \"$k$\": K, \"Method\": [method]*len(precisions)}))\n",
    "\n",
    "pr = pd.concat(pds, ignore_index=True)\n",
    "sns.lineplot(data=pr, x=\"$k$\", y=\"Recall@$k$\", hue=\"Method\", style=\"Method\", ax=axs[1])\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "datasets = {\n",
    "    \"spider\": [\"spider\", \"spider_syn\", \"spider_realistic\", \"spider_dr\"],\n",
    "    \"bird\": [\"bird\"],\n",
    "    \"fiben\": [\"fiben\"],\n",
    "}\n",
    "result_dirs = {\n",
    "    \"spider\": Path(\"../results/test/silver-sun-65/k5ou2ykv\"),\n",
    "    \"bird\": Path(\"../results/test/happy-dew-65/ey4tt3n2\"),\n",
    "    \"fiben\": Path(\"../results/test/electric-donkey-66/sj2wkc2b\"),\n",
    "}\n",
    "pds = []\n",
    "N = 16\n",
    "methods = [\"DBCᴏᴘɪʟᴏᴛ\", \"DPR\", \"CRUSH$_{\\mathrm{SXFMR}}$\", \"CRUSH$_{\\mathrm{BM25}}$\", \"SXFMR\", \"BM25\"]\n",
    "for method in methods:\n",
    "    scores = {\n",
    "        \"AP\": Counter(),\n",
    "        \"n\": Counter(),\n",
    "    }\n",
    "    for dataset, tests in datasets.items():\n",
    "        with Path(f\"../data/{dataset}/schemas.json\").open(\"r\") as f:\n",
    "            schemas = json.load(f)\n",
    "            \n",
    "        for test in tests:\n",
    "            if method == \"DPR\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_dense_true.json\"\n",
    "            elif method == \"CRUSH$_{\\mathrm{BM25}}$\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"crush4sql_{test}_sparse_false.json\"\n",
    "            elif method == \"CRUSH$_{\\mathrm{SXFMR}}$\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"crush4sql_{test}_dense_false.json\"\n",
    "            elif method == \"SXFMR\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_dense_false.json\"\n",
    "            elif method == \"BM25\":\n",
    "                result_file = Path(\"../results\") / \"retrieval\" / f\"{test}_sparse_false.json\"\n",
    "            elif method == \"DBCᴏᴘɪʟᴏᴛ\":\n",
    "                result_file = result_dirs[dataset] / f'{test.replace(dataset, \"test\")}.json'\n",
    "\n",
    "            with result_file.open() as file:\n",
    "                results = json.load(file)\n",
    "\n",
    "            for it in results:\n",
    "                gold_schema = it[\"schema\"]\n",
    "                gold_tables = [\n",
    "                    f'{gold_schema[\"database\"]}.{tbl[\"name\"]}'\n",
    "                    for tbl in gold_schema[\"metadata\"]\n",
    "                ]\n",
    "                gold = set(gold_tables)\n",
    "\n",
    "                pred_dbs = []\n",
    "                pred_tables = []\n",
    "                for pred in it[\"pred_schemas\"]:\n",
    "                    pred_dbs.append(pred[\"database\"])\n",
    "                    pred_tables.extend(\n",
    "                        f'{pred[\"database\"]}.{tbl}'\n",
    "                        for tbl in pred[\"tables\"]\n",
    "                    )\n",
    "\n",
    "                Ps, Rs = [1], [0]\n",
    "                for k in range(1, N):\n",
    "                    cands = set(pred_tables[:k])\n",
    "                    tp = len(cands & gold)\n",
    "                    p_k = tp / len(cands) if len(cands) else 0\n",
    "                    r_k = tp / len(gold) if len(gold) else 0\n",
    "\n",
    "                    Ps.append(p_k)\n",
    "                    Rs.append(r_k)\n",
    "                    \n",
    "                AP = auc(Rs, Ps)\n",
    "                scores[\"AP\"][len(schemas[gold_schema[\"database\"]])] += AP\n",
    "                scores[\"n\"][len(schemas[gold_schema[\"database\"]])] += 1\n",
    "                \n",
    "    mAP = []\n",
    "    K = []\n",
    "    for k in range(20):\n",
    "        if scores[\"n\"][k] != 0:\n",
    "            mAP.append(scores[\"AP\"][k] / scores[\"n\"][k])\n",
    "            K.append(k)\n",
    "\n",
    "    pds.append(pd.DataFrame({\"mAP\": mAP, \"Table Number\": K, \"Method\": [method]*len(K)}))\n",
    "\n",
    "pr = pd.concat(pds, ignore_index=True)\n",
    "sns.lineplot(data=pr, x=\"Table Number\", y=\"mAP\", hue=\"Method\", style=\"Method\", marker='o', ax=axs[0])\n",
    "axs[0].set_title('(a)', fontsize=18)\n",
    "axs[1].set_title('(b)', fontsize=18)\n",
    "\n",
    "sns.despine()\n",
    "plt.savefig('table_number.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d755c1-e50a-47bc-987c-648184e4aac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
